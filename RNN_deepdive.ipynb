{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59649e59-d2a3-4eab-b764-ec0dc4c15735",
   "metadata": {},
   "source": [
    "# Predicting the Next Word: Deep dive into RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec1f657-da9c-4b3b-988f-4561866d86df",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1215d37a-95c8-4d0d-943f-1081c0457c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Sample token list\n",
    "rnn_tokens = ['the', 'sun', 'rises', 'in', 'the', 'east', 'the', 'sun', 'sets', 'in', 'the', 'west']\n",
    "word2idx = {word: i for i, word in enumerate(set(rnn_tokens))}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "\n",
    "# Create training sequences\n",
    "sequences = [(word2idx[rnn_tokens[i]], word2idx[rnn_tokens[i+1]]) for i in range(len(rnn_tokens) - 1)]\n",
    "\n",
    "class WordDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.pairs[idx]\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "dataset = WordDataset(sequences)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd7b55-8d31-47d0-b523-ba203b809298",
   "metadata": {},
   "source": [
    "Implementing RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e14ffab6-e337-4515-823b-f99d875156d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN:\n",
    "    def __init__(self, vocab_size, embedding_dim=10, hidden_dim=16):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Embedding matrix (vocab_size x embedding_dim)\n",
    "        self.embed = torch.randn(vocab_size, embedding_dim, requires_grad=True)\n",
    "\n",
    "        # RNN weights\n",
    "        self.Wxh = torch.randn(embedding_dim, hidden_dim, requires_grad=True)\n",
    "        self.Whh = torch.randn(hidden_dim, hidden_dim, requires_grad=True)\n",
    "        self.bh = torch.zeros(hidden_dim, requires_grad=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.Why = torch.randn(hidden_dim, vocab_size, requires_grad=True)\n",
    "        self.by = torch.zeros(vocab_size, requires_grad=True)\n",
    "\n",
    "        # Track all parameters\n",
    "        self.params = [self.embed, self.Wxh, self.Whh, self.bh, self.Why, self.by]\n",
    "\n",
    "    def forward(self, x_idx, h_prev):\n",
    "        # Get embedding for input word\n",
    "        x_embed = self.embed[x_idx]  # (batch, embedding_dim)\n",
    "\n",
    "        # RNN cell: h_t = tanh(Wxh * x + Whh * h + b)\n",
    "        h_new = torch.tanh(x_embed @ self.Wxh + h_prev @ self.Whh + self.bh)\n",
    "\n",
    "        # Output logits\n",
    "        logits = h_new @ self.Why + self.by\n",
    "\n",
    "        return logits, h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb63e85f-3c02-45ae-a0ea-52c66f8b7dd9",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76bd99c-676b-4237-bdba-fc88d5243d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 39.5475\n",
      "Epoch 2, Loss: 38.8811\n",
      "Epoch 3, Loss: 34.5613\n",
      "Epoch 4, Loss: 30.8859\n",
      "Epoch 5, Loss: 27.9686\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "vocab_size = len(word2idx)\n",
    "model = SimpleRNN(vocab_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.params, lr=0.01)\n",
    "\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# One training loop\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in loader:\n",
    "        h = torch.zeros(x_batch.size(0), model.hidden_dim)  # Initial hidden state\n",
    "\n",
    "        logits, h_new = model.forward(x_batch, h)  # One step RNN\n",
    "\n",
    "        loss = loss_fn(logits, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08495821-4355-47a8-ad99-3ea2366ec403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57c849e1-5462-4c5a-9d4b-326da736bf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03f9708b-8751-4ab2-8d5d-24b503f72e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8674,  1.3481,  0.5546, -0.6112,  1.0983,  0.4165,  1.5105,  0.8281,\n",
       "          0.9538, -0.5975, -1.6062,  0.9321, -1.7609, -0.3320,  0.0941, -1.4093],\n",
       "        [ 0.5549, -1.2707,  0.7994, -0.1094, -0.8315, -0.8924, -1.4619, -0.9835,\n",
       "          0.8612, -0.6127, -0.6205,  2.7250, -1.0205,  2.9810, -1.0786, -0.2745],\n",
       "        [ 1.4266, -0.9023, -0.6765, -0.7307,  0.1673, -1.2404, -0.9419, -1.2360,\n",
       "         -1.5414,  2.1274,  1.9435, -1.6444, -0.6260, -0.8259,  2.3127,  0.9850],\n",
       "        [ 0.9234, -0.4823, -0.9553, -1.3625, -1.5849, -2.3466, -0.3243,  0.3011,\n",
       "         -0.2848, -1.4307, -0.4501, -0.2041, -0.1597, -0.8758,  0.0830,  0.1121],\n",
       "        [-0.7074, -0.5669, -0.3143, -0.1969, -0.8108,  0.7616,  0.0605,  1.0848,\n",
       "          2.1813, -1.6685,  0.4222,  1.0246,  1.0018,  0.8114,  1.7322,  0.7136],\n",
       "        [ 0.1161, -1.0974,  0.9627,  0.0634,  0.4236,  1.9618, -0.0185, -0.7070,\n",
       "         -1.4340,  1.3353, -2.8229,  0.5834,  0.0860, -0.1003, -0.7557, -0.7512],\n",
       "        [ 0.2721, -0.2643,  0.0425,  0.3463, -2.2373,  1.7074, -1.1097, -0.2125,\n",
       "          0.8551,  0.4631, -1.0409, -0.6927, -0.6466, -0.9703, -1.2961,  1.3406],\n",
       "        [-1.1073, -0.2439, -0.1833,  1.3777,  0.1142, -0.3428, -2.2996, -1.3265,\n",
       "          0.7245, -0.2612, -0.5114,  0.2816, -0.5078, -0.3977, -0.6451, -0.6827],\n",
       "        [ 0.1732,  0.1410, -0.6640,  2.7168, -2.4040, -1.3754,  0.5052,  0.1562,\n",
       "         -1.2592,  0.1153,  0.4071,  0.2249,  2.3345, -0.5063, -0.6988,  0.4086],\n",
       "        [ 0.7541,  0.6836, -0.3239,  0.4010, -0.1880, -0.2838,  0.6075, -0.4431,\n",
       "          1.0642, -0.5666, -0.7434, -0.8963, -0.3787,  1.4284,  0.5505, -1.1370],\n",
       "        [-0.4442,  0.9365, -0.3111,  0.5961,  0.2428,  1.2367,  0.1025,  0.8993,\n",
       "          1.0350,  1.3964, -1.0556, -0.5793, -0.2785,  0.5498, -0.8553, -1.6798],\n",
       "        [-0.3889, -1.7917, -0.9952, -0.0414,  0.5759,  0.5568,  0.1168,  0.8276,\n",
       "          0.5932, -2.9938,  0.7040,  0.8818, -0.5391,  0.5186, -0.4365,  1.3818],\n",
       "        [-0.3018, -0.6275,  0.4490, -0.2818,  1.6667,  1.5635, -0.1830,  0.1583,\n",
       "          0.7607, -0.1395,  0.2105, -0.1389, -1.3981, -1.8411, -1.0470, -0.8380],\n",
       "        [ 0.5182, -0.4467, -1.6363,  0.4145, -1.4773,  1.0377, -1.3000, -0.1684,\n",
       "         -1.1680,  0.1284, -1.3749, -1.4009, -0.0580,  1.1192, -1.2344, -0.0214],\n",
       "        [-0.4831, -1.2671, -0.7248,  0.2438,  0.1855, -1.4532,  0.2857,  0.6466,\n",
       "         -0.3404, -1.2990,  0.6197, -0.6197, -1.0436, -0.0972,  0.4691,  1.9887],\n",
       "        [ 0.0838, -1.7751, -0.6876, -1.9533, -0.1167,  0.5906, -1.3542, -1.1444,\n",
       "         -1.7152, -0.0373, -0.2423,  0.0046,  0.2605, -0.8400,  1.0289,  1.1403]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Whh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4206c33-90f3-451c-b3ab-4c8cfd156889",
   "metadata": {},
   "source": [
    "generate text with step by step execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc78de04-9e52-4c23-91e7-2fc45a2a994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rises west sets in west the rises west sets rises\n"
     ]
    }
   ],
   "source": [
    "def generate_text(start_word, model, word2idx, idx2word, max_len=10):\n",
    "    model.eval = lambda: None  # dummy to simulate eval mode\n",
    "    idx = word2idx[start_word]\n",
    "    words = [start_word]\n",
    "    h = torch.zeros(1, model.hidden_dim)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits, h = model.forward(torch.tensor([idx]), h)\n",
    "        idx = torch.argmax(logits, dim=1).item()\n",
    "        words.append(idx2word[idx])\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "print(generate_text(\"the\", model, word2idx, idx2word, max_len=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ce759-8eac-484b-8a41-c20cfa72cdbe",
   "metadata": {},
   "source": [
    "## Step by step execution for deeper understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edde839-6e49-4f79-b31d-d4a4be8613c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b83f01-7f10-4424-9f15-e790b97358d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['the', 'sun', 'rises', 'in', 'the', 'east']\n",
    "word2idx = {word: i for i, word in enumerate(set(tokens))}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "309c97fc-0d0c-4b3b-901d-3affc6501b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in': 0, 'the': 1, 'sun': 2, 'rises': 3, 'east': 4}\n",
      "{0: 'in', 1: 'the', 2: 'sun', 3: 'rises', 4: 'east'}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)\n",
    "print(idx2word)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23145cb-e024-4324-bf85-2deafd3a2a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs (indices): [(1, 2), (2, 3), (3, 0), (0, 1), (1, 4)]\n"
     ]
    }
   ],
   "source": [
    "sequences = [(word2idx[tokens[i]], word2idx[tokens[i + 1]]) for i in range(len(tokens) - 1)]\n",
    "print(\"Training pairs (indices):\", sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f131009e-1a1e-45fe-8099-a20db46e9413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_batch (word indices): tensor([1, 2])\n",
      "y_batch (target indices): tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x_batch = torch.tensor([sequences[0][0], sequences[1][0]])  # inputs: 'the', 'sun'\n",
    "y_batch = torch.tensor([sequences[0][1], sequences[1][1]])  # targets: 'sun', 'rises'\n",
    "print(\"\\nx_batch (word indices):\", x_batch)\n",
    "print(\"y_batch (target indices):\", y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dd1014-0265-420d-b53d-dbb1f55323aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 5\n",
    "hidden_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7856637a-f85c-4749-8cee-9635548f3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.randn(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf14c765-2bce-4f6f-add6-20d0bfd86614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6945, -0.7766, -0.9094, -0.7208, -0.3058],\n",
       "        [ 0.4009,  1.3930,  1.3562, -0.4178,  0.1735],\n",
       "        [-0.2296,  1.0821,  0.8929,  1.3625, -0.9358],\n",
       "        [ 1.2505, -0.3129,  0.5570,  0.9088, -0.1406],\n",
       "        [ 0.7679, -0.7273, -0.5810,  0.8826, -0.7667]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "483980d6-b187-4a63-b1d8-b87e7cd70684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "478ca390-a12e-4ff7-bcbc-99b2111f5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN weights\n",
    "Wxh = torch.randn(embedding_dim, hidden_dim)\n",
    "Whh = torch.randn(hidden_dim, hidden_dim)\n",
    "bh = torch.zeros(hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d8f7e23-1535-4f6f-9f4b-41d6471e0486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4577, -0.8893,  0.4595, -0.5254],\n",
       "        [-0.5251, -1.9444,  0.6279, -1.8165],\n",
       "        [-0.0880, -0.3282,  0.5785, -2.1097],\n",
       "        [ 0.3468, -0.2600,  0.6679,  0.9620],\n",
       "        [-1.4054,  0.7063,  1.2270,  2.1211]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00cd5a2f-21b6-47fa-a946-276eb8ee4c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2006,  0.6899, -0.8724,  0.6135],\n",
       "        [-1.2007,  0.1932,  0.3728,  0.0152],\n",
       "        [ 0.7185,  0.0255,  1.3050, -0.7606],\n",
       "        [-0.4692,  1.4785,  0.7028,  0.9181]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Whh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc37afe-525f-43d3-973b-bd65119b444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68efc6f5-20aa-4e5d-b68a-32c6ae9068d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer weights\n",
    "Why = torch.randn(hidden_dim, vocab_size)\n",
    "by = torch.zeros(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7cd426f-7010-426f-a02d-a0ae83511636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7660, -0.4987,  1.3216,  0.0227, -0.0946],\n",
       "        [-0.2630, -0.2602, -0.5839, -0.3715,  0.1578],\n",
       "        [ 1.9842, -0.6254,  0.9436,  0.3605,  0.7815],\n",
       "        [ 2.0140,  0.0899, -0.9838, -1.4917, -0.6184]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b5e66ff-8b79-4fd0-b984-60b6aa0f2550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45024b37-a28b-4a3c-a247-3919e09155fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embeddings:\n",
      " tensor([[ 0.4009,  1.3930,  1.3562, -0.4178,  0.1735],\n",
      "        [-0.2296,  1.0821,  0.8929,  1.3625, -0.9358]])\n",
      "Shape of embeddings: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "x_embed = embedding[x_batch]  # shape: (batch_size, embedding_dim)\n",
    "print(\"\\nEmbeddings:\\n\", x_embed)\n",
    "print(\"Shape of embeddings:\", x_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d029c844-1443-46cc-967b-b64e3aa47975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial batch size:\n",
      " 2\n",
      "\n",
      "Initial hidden state:\n",
      " tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = x_batch.shape[0]\n",
    "print(\"\\nInitial batch size:\\n\", batch_size)\n",
    "h_prev = torch.zeros(batch_size, hidden_dim)\n",
    "print(\"\\nInitial hidden state:\\n\", h_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10722d4f-5dc8-4610-9708-c7c3ff40c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated hidden state:\n",
      " tensor([[-0.7841, -0.9972,  0.9444, -1.0000],\n",
      "        [ 0.7763, -0.9967,  0.6923, -0.9997]])\n",
      "Shape of hidden state: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "h_t = torch.tanh(x_embed @ Wxh + h_prev @ Whh + bh)\n",
    "print(\"\\nUpdated hidden state:\\n\", h_t)\n",
    "print(\"Shape of hidden state:\", h_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ed44bfd-5a5d-450d-a69f-4a9e058b18c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logits:\n",
      " tensor([[-1.2626, -0.0301,  1.4209,  2.1846,  1.2733],\n",
      "        [ 0.9934, -0.6506,  3.2447,  2.1287,  0.9286]])\n",
      "Shape of logits: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "logits = h_t @ Why + by\n",
    "print(\"\\nLogits:\\n\", logits)\n",
    "print(\"Shape of logits:\", logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "749e9828-8d82-4983-8e24-6b2d67227e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross entropy loss: 1.5084009170532227\n"
     ]
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits, y_batch)\n",
    "print(\"\\nCross entropy loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "245079e4-5fbc-4169-bd56-610ee599ba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted next word indices: tensor([3, 2])\n",
      "Predicted words: ['rises', 'sun']\n"
     ]
    }
   ],
   "source": [
    "predicted_indices = torch.argmax(logits, dim=1)\n",
    "predicted_words = [idx2word[i.item()] for i in predicted_indices]\n",
    "print(\"\\nPredicted next word indices:\", predicted_indices)\n",
    "print(\"Predicted words:\", predicted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "060ba611-9edf-4f9b-a570-c5cd75ab77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wxh (input to hidden weights): torch.Size([5, 4])\n",
      "Whh (hidden to hidden weights): torch.Size([4, 4])\n",
      "bh (hidden bias): torch.Size([4])\n",
      "Why (hidden to output weights): torch.Size([4, 5])\n",
      "by (output bias): torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(\"Wxh (input to hidden weights):\", Wxh.shape)\n",
    "print(\"Whh (hidden to hidden weights):\", Whh.shape)\n",
    "print(\"bh (hidden bias):\", bh.shape)\n",
    "print(\"Why (hidden to output weights):\", Why.shape)\n",
    "print(\"by (output bias):\", by.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c29b8-209f-4f59-8459-272dbe401fbd",
   "metadata": {},
   "source": [
    "## issues with RNNs\n",
    "\n",
    "- In an RNN, gradients are propagated backward through time during training.\n",
    "- This involves **repeated multiplications** of gradient values at each time step.\n",
    "\n",
    "- If the recurrent weights are **small (<1)**, these repeated multiplications cause gradients to:\n",
    "  → **Shrink exponentially** with each time step.\n",
    "  → Eventually become **very close to zero** — this is known as the **vanishing gradient problem**.\n",
    "\n",
    "- What this means:\n",
    "  → **Earlier time steps receive almost no learning signal**.\n",
    "  → The model struggles to **retain and learn long-term dependencies** in sequences.\n",
    "  → RNNs end up relying mostly on **recent inputs**, forgetting information from earlier in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7539dd-da31-4cf6-ad58-c3663be39bf4",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "How Do LSTMs Help?\n",
    "LSTMs have cell states and gating mechanisms (forget, input, output) that control the flow of information.\n",
    "\n",
    "This allows the network to retain important information and ignore unimportant details.\n",
    "\n",
    "As a result, gradients don’t vanish/explode as easily, making LSTMs better at long-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d86d4-d8fe-4e34-9214-a2f5c5de09e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python gen_ai",
   "language": "python",
   "name": "gen_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
