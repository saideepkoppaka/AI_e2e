{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrQBEXGf4xk4",
    "outputId": "732a8374-dc19-42f5-8509-d284858ba987"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets evaluate huggingface_hub peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PJ5jgiF22njk",
    "outputId": "7291455b-274a-43f2-9393-558dba053199"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356,
     "referenced_widgets": [
      "d251fa5e41e8414aa62b2a75990c0c04",
      "ec9e2e6f8a8e48b4b8816151f1fa3ae7",
      "d599a716ffbf4655b76df2abe7b57924",
      "03956c674fce4da0a28c82010c4290d1",
      "d5606f2f191a4bfd9b7ce6a71132b396",
      "e84820e359764192ada189a551f90e70",
      "8c0dc4f8ee184d9bbb98a6a6ba9694e2",
      "37192c5c5f3246f88bfda9006f978c76",
      "aff5bf4597fa4e27b106b3e3d744bec7",
      "d0b12839441e4791ae3761b93b74fc6b",
      "e77de2c5959f437bb7228cd33f2dd884",
      "f0cacb42f8d5432d88af5eeb4f36c63e",
      "493dea4d7c3a4585870bebddb4ae0606",
      "e0ed13f1404b41d8ba52128b7dea3221",
      "0c502a43a22f49029fac57f4e54834e6",
      "321e8be03d05443c8ffef823f134225a",
      "86b48e5b42bd4f1cb63c9096b69a83e8",
      "7eb78a6b147a44ee86efb50b4c3ba5cc",
      "8944e0c728044a519e00feb9c699de11",
      "3fcb6d8525d448bf96d6805084c9db8c",
      "3025d3b5a2ec401aba30f26ce0b8e367",
      "cf4aa61ed5e846508de815ddbf279a79",
      "54b869c5989c4027b9437c7b7bbebf86",
      "0aba98a62f374520b91475623c0018bf",
      "63e8a46c737d46fc94cf989990bc5d49",
      "1068ead47ba549e6973b0bcd255518f3",
      "237862db91ab405085e5fd868c9d767a",
      "cf2e8e78c4de4588bf61aa0c61493e99",
      "3e4531e0456a4028b7417173962effaf",
      "cf687e65bd6544f793928eba0d2d19ed",
      "ef68b4812f1a4e4d8c0f3ffbcb106789",
      "cf3ec535d686494bac639ffe1e11ad93",
      "5ed20639ccbf4e40b1c65b14e897c2f4",
      "8ce9e9c961634ecd84dcd18b85a264e8",
      "cdd3d996c35b481bb66244f9abdadd80",
      "3fb3a798ed48499ebf5e495169310595",
      "0a7c85092c9649ec896e6441c9e593e3",
      "a613e683d0984f829fb625431912705c",
      "60def3e24e1b4fc6b1bcda4accaa44fa",
      "c2968ef0f59f4653a25e2e4ff99f28f3",
      "ed44c561db0e4a2899c9f354e4fa5938",
      "9049a62fac3c47cd8b3866bbf912e8b8",
      "c1d8f873165e43e08670b34951a28076",
      "59d2e94eb4ba46d28968aba3630639bd",
      "81cf1ff5be314d21977f622060303bc1",
      "0620579361bd49928981a1427c1ca3ef",
      "e8ff0d043a364133b7346c272d5bf574",
      "1356021523834a67a1de5c3f4a6cc272",
      "28c09e6d9e774efb8dc908020f520b61",
      "b889b556cebf4ffbb4cd75830953bcdc",
      "b090f9e8ad814f2aa480f3a056889780",
      "3b61c171ace54ce9b89eb1c1a8c72cf5",
      "675a1484be134c6f8bba0e6b65b274db",
      "704fccf254f143558185af56a7382163",
      "99c031ff3650438ca161505d8320ee8f"
     ]
    },
    "id": "2GZ6dKx6zpfh",
    "outputId": "6d96cb28-b9b6-40c6-d422-e9a758a0d21e"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load AG News dataset for a clearer fine-tuning improvement\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPicPBIe029d",
    "outputId": "c32be370-38fd-469e-d38b-9773bbe04d77"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEeTI_Wa3JO5",
    "outputId": "62571f9d-836f-41cb-faee-79af732ae218"
   },
   "outputs": [],
   "source": [
    "print(\"Sample News:\", dataset[\"train\"][0][\"text\"])\n",
    "print(\"Label (0 = World, 1 = Sports, 2 = Business, 3 = Sci/Tech):\", dataset[\"train\"][0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ve31oKvr3Z9q",
    "outputId": "89d2d908-3bdb-4081-cf3b-c2027103abba"
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Reduce size for faster demo\n",
    "small_train = dataset[\"train\"].select(range(4000))\n",
    "small_test = dataset[\"test\"].select(range(1000))\n",
    "\n",
    "# Train/Validation Split\n",
    "small_train_test = small_train.train_test_split(test_size=0.2, seed=42)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": small_train_test[\"train\"],\n",
    "    \"validation\": small_train_test[\"test\"],\n",
    "    \"test\": small_test\n",
    "})\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "a5e4d40f06894b8f89d141455a6f8626",
      "5377fd78146344b28a84e19943d7dae0",
      "38003dee6f54491781c5f3d73b2ca8cf",
      "1e4baea7082d426a974b0f9ceab6c376",
      "e54b64ca2aaa4245a5924776f1a70448",
      "e669dd94190345b1bcb20647ac32a567",
      "56d00d4a1e534910afe8264765ef491d",
      "75c4b8b2189e40e6864915226e01a0e3",
      "bfb6f02dffcd4da4ae4dc92ecd804f9f",
      "ba71cf92be454a55a64e276e1895bea3",
      "2d4b1c061c1b48c7891302ce1186a183",
      "432859bb70794bdfb0f330dbe3465059",
      "1f3b2b096b11407296b662e9c2ee670d",
      "0f56a8aaba7f43c9b119d5af92599bee",
      "ed76f6168bee4cdda55fc3cd7b456558",
      "a8541f97dd464de3807a8ce8f43e9d11",
      "bad1a291836c45528da19d1315edb6a0",
      "ef4865bd428045b2863d44a28f3c69ff",
      "941fbbd5e61a45bc8b9f475b4a41eed6",
      "c5f3039797fa4e5c9a087333114e5865",
      "1eab9c00d41244368556066ee47b7516",
      "f7b3f26b289d4456800ef897ed2efa8f",
      "f16093fd289148e19d61bc128cf6e233",
      "b7e9973534cd4c61ba908c5a76b11a0b",
      "625a9d3602cd4456a85799283584302f",
      "4d3ed8481c09467ca77deff475b98c98",
      "2c9a1691687340c9bc1528bc823f61b0",
      "83ccba0a4516419b872ce68abd483052",
      "39074eb4bd924da885e066ee8fb699ee",
      "79dcc4742d804f9098cf54bbbdd57f78",
      "f9b357f5600d4328ac17ff7bd9bb57f4",
      "8bd607b308b24783a7769725b80452fc",
      "3105aa53fecd4f61b48c81d1050f4fb7",
      "862cd22a59424b359e0c9dd1a8601684",
      "d7b78cc34db54dc49c926b0ea08be9f4",
      "4589bd48b054414dac329ca7b9ce8d14",
      "46ec31d4d2574b769e9561a06e3a546d",
      "1dde1eaa1be447ddb71a57387986699b",
      "f8c0f375bf744b46bc5c17a8e4bfdfec",
      "0540b60831aa43e18843d34dd6cec074",
      "9b630bb8c6c74f80986f1dbfcfde2552",
      "f33b5263884d4c5383b6aba0785c172c",
      "458fa4a230b345d2986faa3cda1d5543",
      "fe1ae7ba5c274ffbaa426f6894a5faf9",
      "8542229f1e454a91bdaaea9e334ffb2e",
      "cf1b60e06e4547b99aeb3878e06bbe18",
      "772b9f5f309d44f2847602837cb0bdf5",
      "bda4ac451cee43c185b58ca67b1e2fa8",
      "0c7b9a27417742549270ab0db4f97541",
      "89aadf8ed5204069bc87c1519b78bd80",
      "141fa1eb471d4f62b3bd76586b89336b",
      "5503d1a5bc3c437b89bb99a61882d610",
      "b5687625ee3a46829ea60147b263911a",
      "0fc524a68d894a36a3111428973f5e13",
      "a19336f13ac844428f45860911597fcb",
      "a0ba29783b324b03bf7b6d58c82a0203",
      "64fab6e34d434e6596f45b3c4b55a04d",
      "15cea67ee9794a9fadff60367ec271fb",
      "ddb1417a8b9744a3b639b44d5c7e7729",
      "8a2c1e6d63fe4e8294bfb6e985c5c2ce",
      "8d97a4cc46304e078efdfa73ae099c61",
      "250185f460c444f98377d73b20299b11",
      "46b25221c2cb4a1199fbaa53aaf84add",
      "254d299714ac4a24848ef8a87ac30fbd",
      "86deb2b031db4104aed57e712b4993e7",
      "45adb164fe8e4e568282258a8979fc0e",
      "56be642ff81c4f4cbf6424e93a4a253d",
      "ea5931e215f148c2a319e11f225ac8dc",
      "90a7255dc2fa41bba1001ce39c25df46",
      "5f99b1ee8ba144fba9547fd05e665856",
      "071c882b2ad846f3b946963b842e4dbd",
      "b1869438b70e45c689bc92c3bdda60f6",
      "679ac16a92524895bd48398c968ede28",
      "529754eb7aa84011b28f06ca4ddf20e4",
      "3bdac188e6a646ea8226c03e45faaf74",
      "9cb884ca75104a04a1a33f2f2b9d3b4d",
      "923e4df734f9454d96d4ca3473f3ce78"
     ]
    },
    "id": "RBSe6u7y3qdp",
    "outputId": "fa3f576a-2b23-4894-b651-4b64bace77e0"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qo8QTwPu3ywZ",
    "outputId": "ad168491-4bb1-43d6-a7c3-7c942c7c676e"
   },
   "outputs": [],
   "source": [
    "print(tokenized_datasets[\"train\"][1])\n",
    "#1 indicates pay attention to that token and 0 indicates do not pay attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "69c7ab8934c84147909363c127f60b90",
      "54b188ede37a496aac6ad3384620d829",
      "83e128e593b746528e975efae457e08f",
      "f41a67075cad4fa3bcd8c56baa1ba718",
      "ec4e6868d4ff4f29962f35547c88ec98",
      "47e7e61c4c4b4edc8f5484779d469bbe",
      "167297dabecc43ef80765c42bffa22f6",
      "991aa36b8fb642658df563c140ef7977",
      "30ecbf0d0c1c4cc7b75c3b1e2277d645",
      "a706299e180b40d2b86bf2ec771135fd",
      "4d3d96a7adbf41c2b023346ee23cf1e9"
     ]
    },
    "id": "OmvgTWt33_Ya",
    "outputId": "f0033421-86fc-470b-930d-e7057d5afbd9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6tkrz5J4nsR",
    "outputId": "00c9aa9c-20c4-4093-b9c7-f2f11e417c76"
   },
   "outputs": [],
   "source": [
    "target_modules = [\"query\", \"value\"]  # key layers in attention blocks\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=target_modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2PJ70_wtyNa"
   },
   "outputs": [],
   "source": [
    "# LoRA rank: defines the dimensionality of the low-rank adapter matrices.\n",
    "# A higher rank increases model capacity but also adds more trainable parameters.\n",
    "\n",
    "# LoRA alpha: scaling factor for the LoRA output.\n",
    "# The actual adapter output is scaled by (alpha / rank) to balance with the frozen base model.\n",
    "\n",
    "# Target modules: list of specific layer names in the model where LoRA adapters should be injected.\n",
    "# Typically includes attention-related layers like \"q_proj\" or \"v_proj\" in transformer models.\n",
    "\n",
    "# LoRA dropout: dropout probability applied only to the LoRA adapter output during training.\n",
    "# Helps reduce overfitting, especially on smaller datasets.\n",
    "\n",
    "# Bias setting: controls whether and where to train bias terms.\n",
    "# Options: \"none\" (do not train any biases), \"all\" (train all biases), \"lora_only\" (train only in layers with LoRA).\n",
    "\n",
    "# Task type: specifies the kind of downstream task for which the model is being fine-tuned.\n",
    "# Examples: SEQ_CLS (sequence classification), CAUSAL_LM (language modeling), TOKEN_CLS (token classification), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8kM6zA9408f",
    "outputId": "8e53acd9-331f-4fdc-e4c1-26e25da6b906"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "print(pipe(\"The stock market closed higher today after positive earnings reports.\"))\n",
    "print(pipe(\"The player scored a hat trick in the championship game.\"))\n",
    "#0 = World, 1 = Sports, 2 = Business, 3 = Sci/Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdlQXoB15ASW"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                        # Directory to save model checkpoints and outputs\n",
    "    eval_strategy=\"epoch\",                  # Evaluate at the end of every epoch\n",
    "    save_strategy=\"epoch\",                        # Save checkpoint at the end of every epoch\n",
    "    learning_rate=2e-4,                            # Learning rate for optimizer\n",
    "    per_device_train_batch_size=8,                 # Batch size per device (GPU/TPU) during training\n",
    "    per_device_eval_batch_size=8,                  # Batch size per device during evaluation\n",
    "    num_train_epochs=2,                            # Total number of training epochs\n",
    "    weight_decay=0.01,                             # Weight decay to apply (for regularization)\n",
    "    logging_dir=\"./logs\",                         # Directory to store logs\n",
    "    push_to_hub=False,                             # Whether to push model to Hugging Face Hub\n",
    "    report_to=\"none\"                               # Disable logging to external tools like WandB/Comet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4ZzyYz95vrJ"
   },
   "outputs": [],
   "source": [
    "# Load Hugging Face's built-in evaluation library\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Load the \"accuracy\" metric — this will download a standard implementation for accuracy scoring\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# Define a custom compute_metrics function that the Trainer will use during evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    # eval_pred is a tuple: (model_outputs, true_labels)\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits (raw model outputs) into predicted class indices\n",
    "    # The model outputs a vector of scores for each class (e.g., [0.2, 0.8])\n",
    "    # np.argmax selects the index with the highest score, i.e., the predicted label\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Compare predicted labels with true labels and calculate accuracy\n",
    "    # accuracy.compute returns a dictionary, e.g., {\"accuracy\": 0.89}\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "YBojQVTT6Ab_",
    "outputId": "7de8fd5e-3f90-4e78-8299-a3bff946cc07"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "FtBbDQVq6q9K",
    "outputId": "77318ae5-9a58-4600-8d68-e6d89e8d7eb9"
   },
   "outputs": [],
   "source": [
    "results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2o6PzdF7nL3",
    "outputId": "4d1aaee1-8a90-4068-f22b-faad8840e598"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=trainer.model, tokenizer=tokenizer)\n",
    "#0 = World, 1 = Sports, 2 = Business, 3 = Sci/Tech\n",
    "print(pipe(\"The stock market closed higher today after positive earnings reports.\"))\n",
    "print(pipe(\"The player scored a hat trick in the championship game.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "b4f54888920241e78b088f661e47a8f6",
      "7860cbdc912a451b85d69bc146480272",
      "50ed67f78f0941c5b5b40c10e0bc3af8",
      "a68453a288b444fe9bcd158ee886cac1",
      "308b34fd62f94bbc9407de6f99cd4520",
      "cf124dfd316d45fa95164309aad88fa7",
      "18ddedffab1242f290ce4644e477c87a",
      "8469287beb364849909742d5f2f240da",
      "18c9264da0794c6c8368876c24c35c6b",
      "341fd1bfb78b429080d9526608db1f4a",
      "29843bf21abc42b6a23475d4ae951ec9",
      "01470b9746d944dd93067588ee79b953",
      "30041e3d34be424ca0f842ce7f634dd4",
      "1fcce940afd4434a9ce92678d1a2c075",
      "713bcb33aab2458697278e1e287dc4d0",
      "45f35dea7af24050a2a820d8941322af",
      "26a3182bec9d4a03963aee08ae35311e",
      "f3d7c9e2f6134518b74c32e7fd22fee0",
      "e43ade3e8c74491d90cf5b2fc996ddcd",
      "95fd1e7e8df34deb968be2ca897b16dd",
      "a0bbf3fec4bc41a18faa9a5ff402d867",
      "ff8ef4d1d88a4b3f9cec69700d6b6683",
      "f21899a81d0942729ae40f5c6a0b8d01",
      "acf606019b154db5b4ca578d356edc0c",
      "737fb37c65a04744aec96431da7beb90",
      "fc099b3c6972473b99e0dac2824d7901",
      "1e6d77b4c8ad46ecaaf0449e66b3669b",
      "e570aa1e01394d3c9e1b572b0c26a983",
      "12685e1b1c6842e499ec470337873f92",
      "5839e90f28da4fd0a6c7099512fcbeb4",
      "357a0547cf2c49e4a83ea15a3e858771",
      "5735e926aa474080ac8000670dcca9b2",
      "135e7859b53c4525bcb05c88a87b38de",
      "f5064cdb12ca4a83afeb1d8af87de804",
      "8a90febd92924039a8bcf2f5e9c6edc2",
      "31b4395128f64818924d59833d8632ba",
      "27c12e049c514688a0d71a2671f5f4a2",
      "5a90988ca4dc474197523ba7879b4d5c",
      "be1cb54256ff447bae0b175b28cddc13",
      "3714262495e34deaafb0cac16794e236",
      "6dc25f7b9bf446fbbd1950fbb5ed8940",
      "309925b60e06414d89f555903b4aa2eb",
      "60ed4f74b12343bd82ebb9337c51c7b4",
      "89c1e25e7812422685d7b841693e28cd",
      "accf41d45abd4c44bba11b347c779b91",
      "950123c287da40119ee75d31d115b244",
      "5c1b559e1015402a9be8fc5b6b81d4d3",
      "23f0dc9e01ad47c291b550d26db405fc",
      "db44be24dcc446cda1c352d2d203ff3d",
      "3f5d37dfa65e40d19ce17896679d8275",
      "337dc3d152ce457da8516708f2f221bb",
      "aad425ec869a49d5989c1448c20461a3",
      "4d0baae472aa413c8fe9b91f6e57078d"
     ]
    },
    "id": "Ti_CN6Nn771K",
    "outputId": "e0ff6a39-7955-46b3-dd20-4e3e0f6f704f"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Kcyc6YeFLOl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
