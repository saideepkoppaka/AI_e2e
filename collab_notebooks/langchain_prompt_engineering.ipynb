{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXt+OHdN36oe823Y7luVzn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"72iynu2h1xRF","executionInfo":{"status":"ok","timestamp":1750733513669,"user_tz":300,"elapsed":13880,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"807e5a92-a128-4e28-8217-9c644b8d6202"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n","Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n","Collecting langchain_community\n","  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n","  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n","Collecting langchain\n","  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n","Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n","Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n","Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n","Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n","  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Downloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n","Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.65\n","    Uninstalling langchain-core-0.3.65:\n","      Successfully uninstalled langchain-core-0.3.65\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.25\n","    Uninstalling langchain-0.3.25:\n","      Successfully uninstalled langchain-0.3.25\n","Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.26 langchain-core-0.3.66 langchain_community-0.3.26 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["langchain","langchain_core"]},"id":"25dc3fcb0a6a40e29899c1eeac31ffb7"}},"metadata":{}}],"source":["# 1. Install necessary packages\n","!pip install openai langchain langchain_community"]},{"cell_type":"code","source":["# 2. Import libraries\n","import os\n","from langchain.llms import OpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain"],"metadata":{"id":"-VVykttY2A38","executionInfo":{"status":"ok","timestamp":1750733951646,"user_tz":300,"elapsed":13,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","openai_token = userdata.get('OPENAI_API_KEY')\n","import os\n","os.environ['OPENAI_API_KEY'] = openai_token"],"metadata":{"id":"WYgJw-K64Ii7","executionInfo":{"status":"ok","timestamp":1750734632216,"user_tz":300,"elapsed":314,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# 4. Initialize the OpenAI LLM wrapper\n","llm = OpenAI(temperature=0)"],"metadata":{"id":"1k-NA1PC5b0S","executionInfo":{"status":"ok","timestamp":1750734640472,"user_tz":300,"elapsed":1056,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# 5. Introduction text for user\n","print(\"\"\"\n","LangChain 101: Prompting Techniques Overview\n","\n","This notebook introduces:\n","- One-shot prompting\n","- Few-shot prompting\n","- Chain-of-Thought prompting (CoT)\n","- Importance of well-crafted prompts\n","\n","You will see examples and explanations for each.\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0qaYW-T5epn","executionInfo":{"status":"ok","timestamp":1750734659539,"user_tz":300,"elapsed":3,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"b8d6c121-2065-4799-a751-f1b5b2eaea6d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","LangChain 101: Prompting Techniques Overview\n","\n","This notebook introduces:\n","- One-shot prompting\n","- Few-shot prompting\n","- Chain-of-Thought prompting (CoT)\n","- Importance of well-crafted prompts\n","\n","You will see examples and explanations for each.\n","\n"]}]},{"cell_type":"code","source":["# --- ONE-SHOT PROMPTING ---\n","\n","print(\"\\n--- ONE-SHOT PROMPTING ---\")\n","print(\"\"\"\n","One-shot prompting means giving the model a single prompt with a question or instruction, expecting it to answer directly.\n","\n","It's simple but often less effective for complex tasks because the model has no examples or reasoning guidance.\n","\"\"\")\n","\n","one_shot_prompt = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=\"Q: {question}\\nA:\"\n",")\n","\n","one_shot_chain = LLMChain(llm=llm, prompt=one_shot_prompt)\n","\n","question = \"What is biggest city in united states?\"\n","response = one_shot_chain.run(question=question)\n","\n","print(f\"Prompt:\\n{one_shot_prompt.format(question=question)}\")\n","print(f\"Response:\\n{response.strip()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CanES2eX6t9U","executionInfo":{"status":"ok","timestamp":1750734859781,"user_tz":300,"elapsed":1202,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"aa75d512-f3e0-449d-ca0d-b6d6eeaee5da"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- ONE-SHOT PROMPTING ---\n","\n","One-shot prompting means giving the model a single prompt with a question or instruction, expecting it to answer directly.\n","\n","It's simple but often less effective for complex tasks because the model has no examples or reasoning guidance.\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-13-623937457.py:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n","  one_shot_chain = LLMChain(llm=llm, prompt=one_shot_prompt)\n","/tmp/ipython-input-13-623937457.py:18: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  response = one_shot_chain.run(question=question)\n"]},{"output_type":"stream","name":"stdout","text":["Prompt:\n","Q: What is biggest city in united states?\n","A:\n","Response:\n","The biggest city in the United States is New York City, with a population of over 8.3 million people.\n"]}]},{"cell_type":"code","source":["# --- FEW-SHOT PROMPTING ---\n","\n","print(\"\\n--- FEW-SHOT PROMPTING ---\")\n","print(\"\"\"\n","Few-shot prompting provides the model with a few examples of questions and answers before asking the new question.\n","\n","This helps the model understand the desired format and style, improving accuracy and consistency.\n","\"\"\")\n","\n","few_shot_template = \"\"\"\n","Q: What is the capital of Germany?\n","A: Berlin\n","\n","Q: What is the capital of Italy?\n","A: Rome\n","\n","Q: What is the capital of {country}?\n","A:\"\"\"\n","\n","few_shot_prompt = PromptTemplate(\n","    input_variables=[\"country\"],\n","    template=few_shot_template\n",")\n","\n","few_shot_chain = LLMChain(llm=llm, prompt=few_shot_prompt)\n","\n","country = \"India\"\n","response = few_shot_chain.run(country=country)\n","\n","print(f\"Prompt:\\n{few_shot_prompt.format(country=country)}\")\n","print(f\"Response:\\n{response.strip()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsjTaL507ejB","executionInfo":{"status":"ok","timestamp":1750734929142,"user_tz":300,"elapsed":1369,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"a72ac3ed-3ff5-414c-9eb6-d2cba603c98c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- FEW-SHOT PROMPTING ---\n","\n","Few-shot prompting provides the model with a few examples of questions and answers before asking the new question.\n","\n","This helps the model understand the desired format and style, improving accuracy and consistency.\n","\n","Prompt:\n","\n","Q: What is the capital of Germany?\n","A: Berlin\n","\n","Q: What is the capital of Italy?\n","A: Rome\n","\n","Q: What is the capital of India?\n","A:\n","Response:\n","New Delhi\n"]}]},{"cell_type":"code","source":["# Explanation\n","print(\"\\n--- COMPLEX CHAIN-OF-THOUGHT (CoT) PROMPTING ---\")\n","print(\"\"\"\n","Chain-of-Thought prompting breaks down multi-step reasoning problems step-by-step to guide the model through intermediate logic before arriving at an answer.\n","This is especially useful for word problems and logical reasoning tasks.\n","\"\"\")\n","\n","# 🧱 Template with a worked-out complex example\n","cot_template = \"\"\"\n","Q1: Jane has twice as many pencils as Tom. Tom has 4 pencils. How many pencils do they have together? Let's think step-by-step.\n","\n","Step 1: Tom has 4 pencils.\n","Step 2: Jane has twice as many as Tom, so Jane has 2 × 4 = 8 pencils.\n","Step 3: Total pencils = Tom's pencils + Jane's pencils = 4 + 8 = 12.\n","\n","Answer: 12\n","\n","Q2: {question} Let's think step-by-step.\n","\"\"\"\n","\n","cot_prompt = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=cot_template\n",")\n","\n","cot_chain = LLMChain(llm=llm, prompt=cot_prompt)\n","\n","# 🧪 New complex question\n","new_question = \"A bookstore sells a novel for $10 and a magazine for $3. If Sarah buys 2 novels and 3 magazines, how much does she spend in total?\"\n","\n","# Run the CoT prompt\n","response = cot_chain.run({\"question\": new_question})\n","\n","# 🖨️ Output\n","print(f\"\\nPrompt:\\n{cot_template.strip().format(question=new_question)}\")\n","print(f\"\\nResponse:\\n{response.strip()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DLv6iBTD7vcY","executionInfo":{"status":"ok","timestamp":1750735624947,"user_tz":300,"elapsed":900,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"538bdb54-7ffd-49cd-ae08-27ace869339b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- COMPLEX CHAIN-OF-THOUGHT (CoT) PROMPTING ---\n","\n","Chain-of-Thought prompting breaks down multi-step reasoning problems step-by-step to guide the model through intermediate logic before arriving at an answer.\n","This is especially useful for word problems and logical reasoning tasks.\n","\n","\n","Prompt:\n","Q1: Jane has twice as many pencils as Tom. Tom has 4 pencils. How many pencils do they have together? Let's think step-by-step.\n","\n","Step 1: Tom has 4 pencils.\n","Step 2: Jane has twice as many as Tom, so Jane has 2 × 4 = 8 pencils.\n","Step 3: Total pencils = Tom's pencils + Jane's pencils = 4 + 8 = 12.\n","\n","Answer: 12\n","\n","Q2: A bookstore sells a novel for $10 and a magazine for $3. If Sarah buys 2 novels and 3 magazines, how much does she spend in total? Let's think step-by-step.\n","\n","Response:\n","Step 1: The cost of 2 novels is 2 × $10 = $20.\n","Step 2: The cost of 3 magazines is 3 × $3 = $9.\n","Step 3: Total cost = Cost of novels + Cost of magazines = $20 + $9 = $29.\n","\n","Answer: $29\n"]}]},{"cell_type":"code","source":["\n","print(\"\\n--- IMPORTANCE OF GOOD PROMPTS ---\")\n","print(\"\"\"\n","The quality of your prompt directly impacts the quality of the model's output.\n","\n","Good prompts:\n","- Provide clear instructions\n","- Include examples (few-shot)\n","- Guide the model's reasoning (CoT)\n","- Specify desired format and style\n","\n","Poor prompts can lead to vague, incorrect, or irrelevant responses.\n","\n","LangChain helps structure prompts and chains of prompts for complex workflows.\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K3Wyx3bp-Zbu","executionInfo":{"status":"ok","timestamp":1750735687400,"user_tz":300,"elapsed":57,"user":{"displayName":"saideep koppaka","userId":"13931546610039642335"}},"outputId":"621e8530-d042-4073-e686-17425f6390aa"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- IMPORTANCE OF GOOD PROMPTS ---\n","\n","The quality of your prompt directly impacts the quality of the model's output.\n","\n","Good prompts:\n","- Provide clear instructions\n","- Include examples (few-shot)\n","- Guide the model's reasoning (CoT)\n","- Specify desired format and style\n","\n","Poor prompts can lead to vague, incorrect, or irrelevant responses.\n","\n","LangChain helps structure prompts and chains of prompts for complex workflows.\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"kfidcV8--o4k"},"execution_count":null,"outputs":[]}]}