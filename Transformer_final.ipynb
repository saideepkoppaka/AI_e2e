{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718d1463-21a5-435d-9ba4-d380e2d04db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder-Only Transformer with Causal Masking, <sos>/<eos>, \n",
    "# Attention Mask, Larger Dataset, and Robust Inference\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c841fc7-f79b-4faf-93d9-6851182b62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Prepare a slightly larger dataset with <sos> for all sequences\n",
    "paragraph = [\n",
    "    '<sos>', 'the', 'sun', 'rises', 'in', 'the', 'east', '<eos>',\n",
    "    '<sos>', 'the', 'moon', 'shines', 'at', 'night', '<eos>',\n",
    "    '<sos>', 'stars', 'twinkle', 'in', 'the', 'sky', '<eos>'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc4cd71-c31b-48b4-ac8d-26e3f99fa373",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(paragraph))\n",
    "word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a67d49c-a3a2-4ca9-bbf0-5bef2c99f7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<eos>': 0,\n",
       " '<sos>': 1,\n",
       " 'at': 2,\n",
       " 'east': 3,\n",
       " 'in': 4,\n",
       " 'moon': 5,\n",
       " 'night': 6,\n",
       " 'rises': 7,\n",
       " 'shines': 8,\n",
       " 'sky': 9,\n",
       " 'stars': 10,\n",
       " 'sun': 11,\n",
       " 'the': 12,\n",
       " 'twinkle': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a759c4-2998-4d5c-acab-8440aa1341b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<eos>',\n",
       " 1: '<sos>',\n",
       " 2: 'at',\n",
       " 3: 'east',\n",
       " 4: 'in',\n",
       " 5: 'moon',\n",
       " 6: 'night',\n",
       " 7: 'rises',\n",
       " 8: 'shines',\n",
       " 9: 'sky',\n",
       " 10: 'stars',\n",
       " 11: 'sun',\n",
       " 12: 'the',\n",
       " 13: 'twinkle'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc251575-b7c9-4d48-a5b8-1dbbd94cd9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c65a83-8ce5-4625-a30e-a9baa1aa8f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(paragraph) - 4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05edc1c0-22d3-426d-9e90-3576abf71306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input-output pairs for next-word prediction\n",
    "seq_len = 4\n",
    "inputs, targets = [], []\n",
    "for i in range(len(paragraph) - seq_len):\n",
    "    seq = paragraph[i:i+seq_len]\n",
    "    target = paragraph[i+seq_len]\n",
    "    if '<eos>' in seq:\n",
    "        continue\n",
    "    inputs.append([word2idx[tok] for tok in seq])\n",
    "    targets.append(word2idx[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7546752-5b3b-473d-8cf5-787b01641f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 12, 11, 7],\n",
       " [12, 11, 7, 4],\n",
       " [11, 7, 4, 12],\n",
       " [7, 4, 12, 3],\n",
       " [1, 12, 5, 8],\n",
       " [12, 5, 8, 2],\n",
       " [5, 8, 2, 6],\n",
       " [1, 10, 13, 4],\n",
       " [10, 13, 4, 12],\n",
       " [13, 4, 12, 9]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b1173d8-13a0-48f1-88ae-abad391f5b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 12, 3, 0, 2, 6, 0, 12, 9, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82774960-fc8e-4db0-bbeb-28421ba3a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(inputs)\n",
    "Y = torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35331835-2c93-4da8-aa8c-4000e502b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442f450a-0478-4f48-b053-ed048dc4897d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba9e8da7-5703-4e05-90a1-c70699b2a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Model configuration\n",
    "embed_dim = 16\n",
    "num_heads = 2\n",
    "head_dim = embed_dim // num_heads\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a08d74e-6f52-4106-8be9-0fabd9d9f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learnable parameters\n",
    "embedding_matrix = Parameter(torch.randn(vocab_size, embed_dim))\n",
    "pos_embedding = Parameter(torch.randn(seq_len, embed_dim))\n",
    "W_q = Parameter(torch.randn(embed_dim, embed_dim))\n",
    "W_k = Parameter(torch.randn(embed_dim, embed_dim))\n",
    "W_v = Parameter(torch.randn(embed_dim, embed_dim))\n",
    "W1 = Parameter(torch.randn(embed_dim, embed_dim))\n",
    "b1 = Parameter(torch.zeros(embed_dim))\n",
    "W2 = Parameter(torch.randn(embed_dim, embed_dim))\n",
    "b2 = Parameter(torch.zeros(embed_dim))\n",
    "W_out = Parameter(torch.randn(embed_dim, vocab_size))\n",
    "b_out = Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    embedding_matrix, pos_embedding, W_q, W_k, W_v,\n",
    "    W1, b1, W2, b2, W_out, b_out\n",
    "], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c7532f-721d-448c-905c-5ef0845af8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 214.2892\n",
      "Epoch 10, Loss: 10.2746\n",
      "Epoch 20, Loss: 0.7195\n",
      "Epoch 30, Loss: 0.2090\n",
      "Epoch 40, Loss: 0.1528\n",
      "Epoch 50, Loss: 0.1469\n",
      "Epoch 60, Loss: 0.1360\n",
      "Epoch 70, Loss: 0.0127\n",
      "Epoch 80, Loss: 0.0014\n",
      "Epoch 90, Loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Training loop\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    embedded = embedding_matrix[X] + pos_embedding\n",
    "    Q = embedded @ W_q\n",
    "    K = embedded @ W_k\n",
    "    V = embedded @ W_v\n",
    "\n",
    "    def reshape(x):\n",
    "        return x.view(batch_size, seq_len, num_heads, head_dim).transpose(1, 2)\n",
    "\n",
    "    Qh, Kh, Vh = map(reshape, (Q, K, V))\n",
    "\n",
    "    attn_mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0)\n",
    "    scores = (Qh @ Kh.transpose(-2, -1)) / math.sqrt(head_dim)\n",
    "    scores = scores.masked_fill(attn_mask == 0, float('-inf'))\n",
    "    attn_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    attn_output = attn_weights @ Vh\n",
    "    attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n",
    "\n",
    "    ffn = torch.relu(attn_output @ W1 + b1)\n",
    "    ffn = ffn @ W2 + b2\n",
    "\n",
    "    final_token = ffn[:, -1, :]\n",
    "    logits = final_token @ W_out + b_out\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aec8a44-cd77-48de-b705-da1ca28268c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save model locally in a structured file\n",
    "model_state = {\n",
    "    'embedding_matrix': embedding_matrix.detach(),\n",
    "    'pos_embedding': pos_embedding.detach(),\n",
    "    'W_q': W_q.detach(), 'W_k': W_k.detach(), 'W_v': W_v.detach(),\n",
    "    'W1': W1.detach(), 'b1': b1.detach(), 'W2': W2.detach(), 'b2': b2.detach(),\n",
    "    'W_out': W_out.detach(), 'b_out': b_out.detach(),\n",
    "    'word2idx': word2idx, 'idx2word': idx2word,\n",
    "    'embed_dim': embed_dim, 'seq_len': seq_len, 'num_heads': num_heads\n",
    "}\n",
    "torch.save(model_state, \"decoder_transformer_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381c6af0-f015-47e8-8f1d-4148ec66f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load model and inference function\n",
    "checkpoint = torch.load(\"decoder_transformer_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6596200-ee80-40a9-a52c-1922ce2b6b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = checkpoint['embedding_matrix']\n",
    "pos_embedding = checkpoint['pos_embedding']\n",
    "W_q = checkpoint['W_q']\n",
    "W_k = checkpoint['W_k']\n",
    "W_v = checkpoint['W_v']\n",
    "W1 = checkpoint['W1']\n",
    "b1 = checkpoint['b1']\n",
    "W2 = checkpoint['W2']\n",
    "b2 = checkpoint['b2']\n",
    "W_out = checkpoint['W_out']\n",
    "b_out = checkpoint['b_out']\n",
    "word2idx = checkpoint['word2idx']\n",
    "idx2word = checkpoint['idx2word']\n",
    "embed_dim = checkpoint['embed_dim']\n",
    "seq_len = checkpoint['seq_len']\n",
    "num_heads = checkpoint['num_heads']\n",
    "head_dim = embed_dim // num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d5e8b6a-5b10-4d12-bffb-58fe9d05703e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3655, -1.0750, -0.1643,  0.6425,  1.5937, -1.7208, -0.0904, -0.0357,\n",
       "         -0.0707, -0.7346,  2.1541, -1.5807, -2.5454, -0.5540, -0.1947,  0.5991],\n",
       "        [-1.4843,  0.7852, -0.9336,  2.7172, -0.5522, -0.7768, -1.1033,  0.4119,\n",
       "         -1.2031, -0.2711, -0.5309,  0.2537, -1.7941,  1.6523, -0.9307, -0.5694],\n",
       "        [-0.8823, -0.4147,  2.1827, -1.0573, -0.2713, -0.4346, -1.1253,  0.9946,\n",
       "         -1.0674,  1.9790,  1.0854, -0.9306,  0.0748, -0.2926, -1.6343, -0.3283],\n",
       "        [-0.6138,  0.3872, -0.1049,  0.1742, -0.5154, -1.0625, -0.2511,  0.6225,\n",
       "         -1.0498, -1.4465, -0.6444,  0.6280, -0.6765,  0.4764,  0.9294,  1.4273]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a77446-82b2-4452-af45-fd4e655bc08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6735, -1.3010, -0.5142,  0.1470, -0.4942, -0.6457,  1.6273,  1.1840,\n",
       "         -0.3979,  0.0145,  0.6088, -0.1372, -1.7032, -0.7718,  0.3392,  0.6545],\n",
       "        [-0.8289,  0.2249,  2.5723,  1.2621, -1.5539,  0.0320,  1.2931, -0.2951,\n",
       "          0.3752,  0.6632,  0.7567, -0.7760, -1.3101, -1.3830, -0.3203, -0.1739],\n",
       "        [ 2.5386, -0.4766,  0.5736,  0.5614,  0.7321,  1.1841, -2.4389, -0.0283,\n",
       "         -0.0579,  0.8476, -0.0036,  0.5378, -0.7895, -0.4302,  0.9561, -0.9286],\n",
       "        [ 0.8756,  0.9265, -0.6452,  0.4425, -0.6957, -0.8279, -0.0613, -0.2311,\n",
       "         -1.7024, -0.9615,  0.9508, -0.4698, -2.0479, -0.4157,  0.3622, -0.0191],\n",
       "        [-0.8027,  1.1205,  1.0070,  0.4953, -0.1670, -0.7380,  2.1886,  0.1097,\n",
       "         -1.6248, -1.3093,  0.4047,  0.3114, -1.0942,  0.6767,  1.0555,  0.5374],\n",
       "        [ 1.1496,  1.6786,  0.8893, -1.0376,  0.0752,  0.7339,  1.1957,  0.0477,\n",
       "         -1.2821, -1.0999,  1.0371,  1.3299, -0.9239, -0.1270,  0.1070,  2.0305],\n",
       "        [ 0.7131, -0.0071, -0.5623,  0.4770, -1.5417, -0.1323, -1.0253, -2.2956,\n",
       "         -0.4413, -1.9928,  1.3448,  0.1335,  0.1752, -0.8239, -0.9659, -0.7034],\n",
       "        [-1.3084,  0.8648,  0.7982,  0.5119,  0.3886,  0.3802,  0.1021,  0.6562,\n",
       "         -1.6456, -0.3534, -0.0525,  0.8081, -0.1484, -0.6623, -1.0077,  0.0329],\n",
       "        [-0.9715, -1.4222,  0.0315, -0.5544,  0.4495,  0.2356, -0.7419,  0.0386,\n",
       "         -2.4543,  1.1545, -2.1445,  0.4322, -0.2229,  0.0485,  0.3324,  1.7083],\n",
       "        [ 0.7261, -0.7016, -0.8760, -1.3437, -1.4708, -1.9590, -0.3613,  0.8385,\n",
       "         -2.4075, -0.5022,  1.1302,  0.4509, -1.5793,  0.0663, -0.2553, -0.0864],\n",
       "        [ 0.8716,  0.4838,  1.4337,  0.1498, -0.1034,  0.2836, -0.4643, -0.0464,\n",
       "          0.2030, -0.7292,  0.6906, -0.8009,  1.5510,  0.4634,  0.5373,  1.0105],\n",
       "        [ 0.0628, -0.5339, -0.4271, -0.6549, -0.6122, -1.1123,  0.6642,  0.9835,\n",
       "         -0.0191, -0.0689, -1.3684, -0.9161, -2.3555, -0.2481, -1.3570,  0.0656],\n",
       "        [-0.2106,  0.8903, -0.9903, -0.6011, -2.9967, -1.3496, -1.4617,  0.7612,\n",
       "          1.4786,  0.1304,  0.8186,  0.2551,  1.0489, -0.1377, -0.8301,  1.9767],\n",
       "        [-0.5580,  0.8410,  1.5211, -1.2254,  0.9400,  0.7993,  2.1159, -0.3390,\n",
       "          0.0076,  0.3840, -2.2084,  1.4216, -0.6386, -1.0082,  1.4614,  0.8171],\n",
       "        [ 1.6624, -1.9144, -0.6677, -0.2855,  0.7226,  0.3607,  1.1214, -0.9791,\n",
       "          0.4669, -0.9892, -0.9260, -0.3279, -1.4688, -1.5361,  0.3523, -2.4561],\n",
       "        [ 0.4765, -1.4665,  0.7814,  0.7821, -0.0766,  0.7075,  0.0795, -0.4774,\n",
       "         -0.9836, -0.2223, -1.6482,  1.2896, -0.6489,  3.0351, -0.0215,  0.1261]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba3cfe0e-a446-4dbe-963b-955ae143f6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62ba69a1-fa67-4af8-af44-0f90cb0b8fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prediction utility\n",
    "def predict_next_tokens(input_seq, max_len=5):\n",
    "    model_input = input_seq[:]\n",
    "    for _ in range(max_len):\n",
    "        current_len = len(model_input)\n",
    "        if current_len < seq_len:\n",
    "            pad = ['<sos>'] * (seq_len - current_len)\n",
    "            input_tokens = pad + model_input\n",
    "        else:\n",
    "            input_tokens = model_input[-seq_len:]\n",
    "\n",
    "        input_idx = torch.tensor([[word2idx.get(tok, 0) for tok in input_tokens]])\n",
    "        embedded = embedding_matrix[input_idx] + pos_embedding\n",
    "        Q = embedded @ W_q\n",
    "        K = embedded @ W_k\n",
    "        V = embedded @ W_v\n",
    "\n",
    "        Qh, Kh, Vh = map(lambda x: x.view(1, seq_len, num_heads, head_dim).transpose(1, 2), (Q, K, V))\n",
    "        scores = (Qh @ Kh.transpose(-2, -1)) / math.sqrt(head_dim)\n",
    "        scores = scores.masked_fill(torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(0) == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_output = attn_weights @ Vh\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(1, seq_len, embed_dim)\n",
    "        ffn = torch.relu(attn_output @ W1 + b1)\n",
    "        ffn = ffn @ W2 + b2\n",
    "        final_token = ffn[:, -1, :]\n",
    "        logits = final_token @ W_out + b_out\n",
    "        next_idx = torch.argmax(logits, dim=1).item()\n",
    "        next_word = idx2word[next_idx]\n",
    "        model_input.append(next_word)\n",
    "        if next_word == '<eos>':\n",
    "            break\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e61d67e1-aa34-48b0-a6ee-315792069f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on loaded model:\n",
      "Generated sequence 1: ['<sos>', 'the', 'moon', 'sky', 'in', 'the', 'at', '<eos>']\n",
      "Generated sequence 2: ['<sos>', 'stars', 'in', 'in', 'the', '<eos>']\n",
      "Generated sequence 3: ['<sos>', 'the', 'night', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Predictions on loaded model\n",
    "print(\"\\nPredictions on loaded model:\")\n",
    "print(\"Generated sequence 1:\", predict_next_tokens(['<sos>', 'the', 'moon']))\n",
    "print(\"Generated sequence 2:\", predict_next_tokens(['<sos>', 'stars']))\n",
    "print(\"Generated sequence 3:\", predict_next_tokens(['<sos>', 'the']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9a446-5fbb-475c-aeb0-6139f29302cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python gen_ai",
   "language": "python",
   "name": "gen_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
